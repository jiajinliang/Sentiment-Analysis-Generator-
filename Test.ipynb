{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'all_in_one' from '/Users/innocence-dian/Desktop/CSE 156/Final_Project/156_Final_Project/all_in_one.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import all_in_one as module\n",
    "import importlib\n",
    "importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "-- train data\n",
      "sentiment/train.tsv\n",
      "4582\n",
      "-- dev data\n",
      "sentiment/dev.tsv\n",
      "458\n",
      "-- transforming data and labels\n",
      "  Accuracy on dev is: 0.8187772925764192\n",
      "Prediction: NEGATIVE\n",
      "Words being ignored due to not appearing in training set are: \n",
      "[a]\n",
      "Words being ignored due to mindf (unfrequent in corpus) are: \n",
      "[text]\n",
      "Words being ignored due to maxdf (too frequent in corpus) are: \n",
      "[my, wasthis, was]\n",
      "Words being ignored due to our algorithm are: \n",
      "[minute, system, me, that, my, was, ready, but, they, made, me, wait, now, this, was, very, experience, when, your, so, stay]\n",
      "Remaining words in the vec: \n",
      "[cvs, clinic, doctor, 30, minutes, unpleasant, sick]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "[>                                                           ] 0%\r",
      "[======>                                                     ] 10%\r",
      "[==============================>                             ] 50%\r",
      "[============================================================] 100%\r",
      "Rendering (2/2)                                                    \n",
      "[>                                                           ] 0%\r",
      "[===============>                                            ] 25%\r",
      "[============================================================] 100%\r",
      "Done                                                               \n"
     ]
    }
   ],
   "source": [
    "m = module.Model()\n",
    "o,d = m.pipeline(m.sentiment.train_data[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Went last night for the first time with my boyfriend. Let me start off by saying I'm vegetarian, but my boyfriend is not. I ordered the chicken v mushroom, it\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.sentiment.train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Excellent\n",
      "Prediction: POSITIVE\n",
      "Words being ignored due to not appearing in training set are: \n",
      "None\n",
      "Words being ignored due to mindf (unfrequent in corpus) are: \n",
      "None\n",
      "Words being ignored due to maxdf (too frequent in corpus) are: \n",
      "None\n",
      "Words being ignored due to our algorithm are: \n",
      "None\n",
      "Remaining words in the vec: \n",
      "[excellent]\n",
      "\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for x in o:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import six\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['date'] = ['2016-04-01', '2016-04-02', '2016-04-03']\n",
    "df['calories'] = [2200, 2100, 1500]\n",
    "df['sleep hours'] = [2200, 2100, 1500]\n",
    "df['gym'] = [True, False, False]\n",
    "\n",
    "\n",
    "def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,\n",
    "                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                     ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "\n",
    "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in  six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='w')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return ax\n",
    "\n",
    "a = render_mpl_table(df, header_columns=0, col_width=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = a.get_figure()\n",
    "f.savefig('Fig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "-- train data\n",
      "sentiment/train.tsv\n",
      "4582\n",
      "-- dev data\n",
      "sentiment/dev.tsv\n",
      "458\n",
      "-- transforming data and labels\n"
     ]
    }
   ],
   "source": [
    "import sentiment as sentimentinterface\n",
    "import classify\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(sentimentinterface)\n",
    "print(\"Reading data\")\n",
    "tarfname = \"data/sentiment.tar.gz\"\n",
    "sentiment = sentimentinterface.read_data(tarfname)\n",
    "\n",
    "sentiment.stop_words = sentimentinterface.generate_stop_words(sentiment, diff = 0.4)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentiment.cv = CountVectorizer(min_df = 3)\n",
    "sentiment.cv.fit_transform(sentiment.train_data)\n",
    "sentiment.mindf_stop_words = sentiment.cv.stop_words_\n",
    "sentiment.cv = CountVectorizer(max_df = 0.2)\n",
    "sentiment.cv.fit_transform(sentiment.train_data)\n",
    "sentiment.maxdf_stop_words = sentiment.cv.stop_words_\n",
    "sentiment.cv = CountVectorizer()\n",
    "sentiment.cv.fit_transform(sentiment.train_data)\n",
    "sentiment.training_set_vocabulary = sentiment.cv.vocabulary_\n",
    "\n",
    "sentimentinterface.vectorize_data(sentiment, stop_words = sentiment.stop_words, max_df = 0.2, min_df = 3)\n",
    "cls = classify.train_classifier(sentiment.trainX, sentiment.trainy, C = 3.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    from string import punctuation\n",
    "    s_new = []\n",
    "    s_ignored = []\n",
    "    res = []\n",
    "    for c in s:\n",
    "        if c not in punctuation:\n",
    "            s_new.append(c.lower())\n",
    "        else:\n",
    "            s_new.append(' ')\n",
    "\n",
    "    s = ''.join(c for c in s_new)\n",
    "    #s = [''.join(c for c in s if c not in punctuation)][0]\n",
    "\n",
    "    l = s.split()\n",
    "\n",
    "    for w in l:\n",
    "        if w in sentiment.count_vect.vocabulary_:\n",
    "            if w not in res:\n",
    "                res.append(w)\n",
    "        else:\n",
    "            s_ignored.append(w)\n",
    "#     l = [w for w in l if w in sentiment.count_vect.vocabulary_]\n",
    "\n",
    "    return res, s_ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"If I could do 0 STAR I WOULD DO IT. worst restaurant I have ever try in San Diego and as A Chinese I do shame on the food they named Chinese food. The food was not fresh and both me and my friend have to rush to bathroom all night. Never come back again.\"\n",
    "a,s_ignored = clean(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', '0', 'i', 'i', 'a', 'i']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen = []\n",
    "for w in s_ignored:\n",
    "    if w not in sentiment.training_set_vocabulary:\n",
    "        unseen.append(w)\n",
    "        \n",
    "unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i, 0, i, i, a, i'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \", \".join(unseen)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
