{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment as sentimentinterface\n",
    "import classify\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "-- train data\n",
      "sentiment/train.tsv\n",
      "4582\n",
      "-- dev data\n",
      "sentiment/dev.tsv\n",
      "458\n",
      "-- transforming data and labels\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sentimentinterface)\n",
    "print(\"Reading data\")\n",
    "tarfname = \"data/sentiment.tar.gz\"\n",
    "sentiment = sentimentinterface.read_data(tarfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy on dev is: 0.8187772925764192\n",
      "\n",
      "Reading unlabeled data\n",
      "sentiment/unlabeled.tsv\n",
      "(91524, 2123)\n",
      "Writing predictions to a file\n"
     ]
    }
   ],
   "source": [
    "stop_words = sentimentinterface.generate_stop_words(sentiment, diff = 0.4)\n",
    "sentimentinterface.vectorize_data(sentiment, stop_words = stop_words, max_df = 0.2, min_df = 3)\n",
    "cls = classify.train_classifier(sentiment.trainX, sentiment.trainy, C = 3.7)\n",
    "\n",
    "classify.evaluate(sentiment.devX, sentiment.devy, cls, 'dev')\n",
    "print(\"\\nReading unlabeled data\")\n",
    "unlabeled = sentimentinterface.read_unlabeled(tarfname, sentiment)\n",
    "print(\"Writing predictions to a file\")\n",
    "sentimentinterface.write_pred_kaggle_file(unlabeled, cls, \"data/sentiment-pred.csv\", sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now cls is the optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(sentence, count_vect = sentiment.count_vect):\n",
    "    return count_vect.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, cls = cls):\n",
    "    sentence_vect = vectorize_sentence(sentence)\n",
    "    result = cls.predict(sentence_vect)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Went last night for the first time with my boyfriend. Let me start off by saying I'm vegetarian, but my boyfriend is not. I ordered the chicken v mushroom, it\"\n",
    "print(predict(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now explain why it predicted 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    \n",
    "    s_new = []\n",
    "    s_ignored = []\n",
    "    for c in s:\n",
    "        if c not in punctuation:\n",
    "            s_new.append(c.lower())\n",
    "        else:\n",
    "            s_new.append(' ')\n",
    "            \n",
    "    s = ''.join(c for c in s_new)\n",
    "    #s = [''.join(c for c in s if c not in punctuation)][0]\n",
    "\n",
    "    l = s.split()\n",
    "    \n",
    "    res = []\n",
    "    for w in l:\n",
    "        if w in sentiment.count_vect.vocabulary_:\n",
    "            res.append(w)\n",
    "        else:\n",
    "            s_ignored.append(w)\n",
    "#     l = [w for w in l if w in sentiment.count_vect.vocabulary_]\n",
    "    \n",
    "    print(\"Words being ignored due to not appearing in training set are:\")\n",
    "    if len(s_ignored) == 0:\n",
    "        print(\"None\\n\")\n",
    "    else:\n",
    "        print(s_ignored)\n",
    "        print('')\n",
    "    print(\"Remaining words are: \")\n",
    "    if len(res) == 0:\n",
    "        print(\"None\\n\")\n",
    "    else:\n",
    "        print(res)\n",
    "        print('')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words being ignored due to not appearing in training set are:\n",
      "['last', 'night', 'for', 'the', 'first', 'time', 'with', 'my', 'boyfriend', 'me', 'start', 'off', 'by', 'i', 'm', 'but', 'my', 'boyfriend', 'is', 'i', 'the', 'chicken', 'v', 'it']\n",
      "\n",
      "Remaining words are: \n",
      "['went', 'let', 'saying', 'vegetarian', 'not', 'ordered', 'mushroom']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence_vect = clean(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stop_words(sentence, stop_words = stop_words):\n",
    "    sentence_vect = clean(sentence)\n",
    "    res = []\n",
    "    for w in sentence_vect:\n",
    "        if w in stop_words:\n",
    "            res.append(w)\n",
    "    print(\"Words being ignored due to stop words are: \")\n",
    "    if len(res) == 0:\n",
    "        print(\"None\\n\")\n",
    "    else:\n",
    "        print(res)\n",
    "        print('')\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words being ignored due to not appearing in training set are:\n",
      "['last', 'night', 'for', 'the', 'first', 'time', 'with', 'my', 'boyfriend', 'me', 'start', 'off', 'by', 'i', 'm', 'but', 'my', 'boyfriend', 'is', 'i', 'the', 'chicken', 'v', 'it']\n",
      "\n",
      "Remaining words are: \n",
      "['went', 'let', 'saying', 'vegetarian', 'not', 'ordered', 'mushroom']\n",
      "\n",
      "Words being ignored due to stop words are: \n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_stop_words(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coef(sentence, stop_words = stop_words, cls = cls):\n",
    "    sentence_vect = clean(sentence)\n",
    "    for word in sentence_vect:\n",
    "        if word in sentiment.count_vect.vocabulary_:\n",
    "            print(word,\"\\'s coef:\\t\\t\", cls.coef_[0][sentiment.count_vect.vocabulary_[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words being ignored due to not appearing in training set are:\n",
      "['last', 'night', 'for', 'the', 'first', 'time', 'with', 'my', 'boyfriend', 'me', 'start', 'off', 'by', 'i', 'm', 'but', 'my', 'boyfriend', 'is', 'i', 'the', 'chicken', 'v', 'it']\n",
      "\n",
      "Remaining words are: \n",
      "['went', 'let', 'saying', 'vegetarian', 'not', 'ordered', 'mushroom']\n",
      "\n",
      "went 's coef:\t\t -1.251740858407901\n",
      "let 's coef:\t\t -0.7935660220282503\n",
      "saying 's coef:\t\t -1.3105183912332536\n",
      "vegetarian 's coef:\t\t 1.4565436858852365\n",
      "not 's coef:\t\t -3.322794263373309\n",
      "ordered 's coef:\t\t -1.3488052235512404\n",
      "mushroom 's coef:\t\t 1.7986278279867243\n"
     ]
    }
   ],
   "source": [
    "find_coef(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
